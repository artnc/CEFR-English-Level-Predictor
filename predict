#!/usr/bin/env python3
#
# To run in CLI mode:
#     docker run --rm -it "$(docker build -q .)" ./predict "Hello world"
# To run in server mode:
#     docker run --rm -it -p 8047:8047 "$(docker build -q .)" ./predict

import json
import sys

from cefr_predictor.inference import Model
model = Model("cefr_predictor/models/xgboost.joblib")

if len(sys.argv) == 2:
    print(model.predict_decode([sys.argv[1]])[0][0][:2])
else:
    from flask import Flask, request
    app = Flask(__name__)
    @app.route("/", methods=["POST"])
    def predict():
        body = request.get_data().decode()
        if body and body[0] == "[":
            return json.dumps([
                p[:2]
                for p in model.predict_decode(json.loads(body))[0]
            ])
        else:
            return model.predict_decode([body])[0][0][:2]
    app.run(host='0.0.0.0', port=8047)